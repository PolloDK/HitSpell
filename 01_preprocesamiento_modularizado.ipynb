{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eb948e6-5ba0-4570-a1f0-85e7e4ef566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "import joblib\n",
    "def load_csv(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def clean_text_columns(df, cols):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype(str).str.strip().str.lower()\n",
    "    return df\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    if 'duration_ms' in df.columns:\n",
    "        df['duration_ms'] = df['duration_ms'].fillna(df['duration_ms'].median())\n",
    "    if 'audio_sample_rate' in df.columns:\n",
    "        df['audio_sample_rate'] = df['audio_sample_rate'].fillna(df['audio_sample_rate'].mode()[0])\n",
    "    return df\n",
    "\n",
    "def convert_to_datetime(df, column):\n",
    "    df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "    return df\n",
    "\n",
    "def drop_columns(df, cols_to_drop):\n",
    "    return df.drop(columns=cols_to_drop)\n",
    "\n",
    "def scale_minmax(df, columns_to_scale):\n",
    "    scaler = MinMaxScaler()\n",
    "    df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "    joblib.dump(scaler, \"./models/minmax_scaler.pkl\")\n",
    "    return df\n",
    "\n",
    "def merge_on_mbid(df1, df2):\n",
    "    df = df1.merge(df2, on='mbid', how='inner')\n",
    "    df = df.drop(columns=['title_y', 'artist_y', 'genre_y', 'year_y', 'duration_ms_y'])\n",
    "    df = df.rename(columns={\n",
    "        'title_x': 'title', 'artist_x': 'artist', 'genre_x': 'genre',\n",
    "        'year_x': 'year', 'duration_ms_x': 'duration_ms'\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def encode_binary_column(df, column, positive_val='danceable', negative_val='not_danceable'):\n",
    "    if column == \"high_danceability_value\":\n",
    "            df['danceability_encoded'] = df[column].map({positive_val: 1, negative_val: 0})\n",
    "    else:\n",
    "            df[column + '_encoded'] = df[column].map({positive_val: 1, negative_val: 0})\n",
    "    return df.drop(columns=[column])\n",
    "\n",
    "def encode_binary_multiple(df, binary_cols):\n",
    "    for col in binary_cols:\n",
    "        unique_vals = df[col].dropna().unique()\n",
    "        df[col] = df[col].map({unique_vals[0]: 0, unique_vals[1]: 1})\n",
    "    return df\n",
    "\n",
    "def one_hot_encode(df, cols):\n",
    "    return pd.get_dummies(df, columns=cols, drop_first=True)\n",
    "\n",
    "def frequency_encode(df, cols):\n",
    "    for col in cols:\n",
    "        freq_map = df[col].value_counts().to_dict()\n",
    "        df[col] = df[col].map(freq_map)\n",
    "    return df\n",
    "\n",
    "def final_cleanup(df):\n",
    "    if 'release_date' in df.columns:\n",
    "        df['release_year'] = df['release_date'].dt.year\n",
    "        df['release_year'].fillna(df['release_year'].median(), inplace=True)\n",
    "        df.drop(columns='release_date', inplace=True)\n",
    "\n",
    "    num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for col in num_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    cat_cols = df.select_dtypes(include='object').columns\n",
    "    for col in cat_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "    return df\n",
    "\n",
    "def scale_standard(df):\n",
    "    scale_cols = [\n",
    "        'high_danceability_probability', 'high_gender_probability', 'high_mood_acoustic_probability',\n",
    "        'high_mood_aggressive_probability', 'high_mood_electronic_probability', 'high_mood_happy_probability',\n",
    "        'high_mood_party_probability', 'high_mood_relaxed_probability', 'high_mood_sad_probability',\n",
    "        'high_moods_mirex_probability', 'high_timbre_probability', 'high_tonal_atonal_probability',\n",
    "        'high_voice_instrumental_probability', 'low_average_loudness', 'low_dynamic_complexity',\n",
    "        'low_mfcc_mean_0', 'low_mfcc_mean_1', 'low_mfcc_mean_2', 'low_mfcc_mean_3', 'low_mfcc_mean_4',\n",
    "        'low_mfcc_mean_5', 'low_mfcc_mean_6', 'low_mfcc_mean_7', 'low_mfcc_mean_8', 'low_mfcc_mean_9',\n",
    "        'low_mfcc_mean_10', 'low_mfcc_mean_11', 'low_mfcc_mean_12', 'audio_sample_rate', 'audio_bit_rate',\n",
    "        'audio_equal_loudness', 'audio_analysis_sample_rate', 'audio_length', 'audio_replay_gain',\n",
    "        'low_key_strength', 'low_chords_changes_rate', 'low_tuning_frequency', 'low_danceability',\n",
    "        'low_onset_rate', 'low_bpm', 'low_beats_count', 'danceability_encoded'\n",
    "    ]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    df[scale_cols] = scaler.fit_transform(df[scale_cols])\n",
    "\n",
    "    joblib.dump(scaler, \"./models/scaler.pkl\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98ab03aa-d356-4541-b77a-b8c60cac1f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62386/3118468584.py:6: DtypeWarning: Columns (9,10,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(path)\n",
      "/tmp/ipykernel_62386/3118468584.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['release_year'].fillna(df['release_year'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Cargar datasets\n",
    "pop_df = load_csv(\"popularity.csv\")\n",
    "feat_df = load_csv(\"features_full_final.csv\")\n",
    "\n",
    "# Limpiar texto\n",
    "pop_df = clean_text_columns(pop_df, ['title', 'artist', 'genre'])\n",
    "feat_df = clean_text_columns(feat_df, ['title', 'artist', 'genre'])\n",
    "\n",
    "# Rellenar nulos\n",
    "pop_df = fill_missing_values(pop_df)\n",
    "feat_df = fill_missing_values(feat_df)\n",
    "\n",
    "# Convertir fechas y eliminar columnas irrelevantes\n",
    "pop_df = convert_to_datetime(pop_df, 'release_date')\n",
    "pop_df = drop_columns(pop_df, ['artist_followers', 'extraction_date', 'artist_popularity', 'artist_id', 'spotify_id'])\n",
    "\n",
    "# Escalar variables numéricas con MinMaxScaler\n",
    "pop_df = scale_minmax(pop_df, ['duration_ms'])\n",
    "\n",
    "# Unir datasets por 'mbid'\n",
    "df = merge_on_mbid(pop_df, feat_df)\n",
    "\n",
    "# Codificación binaria personalizada\n",
    "if 'high_danceability_value' in df.columns:\n",
    "    df = encode_binary_column(df, 'high_danceability_value', 'danceable', 'not_danceable')\n",
    "\n",
    "# Codificación binaria\n",
    "binary_cols = [\n",
    "    'high_gender_value', 'high_mood_acoustic_value', 'high_mood_aggressive_value',\n",
    "    'high_mood_electronic_value', 'high_mood_happy_value', 'high_mood_party_value',\n",
    "    'high_mood_relaxed_value', 'high_mood_sad_value', 'high_timbre_value',\n",
    "    'high_tonal_atonal_value', 'high_voice_instrumental_value', 'audio_downmix',\n",
    "    'low_key_scale', 'low_chords_scale'\n",
    "]\n",
    "df = encode_binary_multiple(df, binary_cols)\n",
    "\n",
    "# One-hot encoding a columnas seleccionadas\n",
    "df = one_hot_encode(df, ['genre', 'high_genre_electronic_value', 'high_moods_mirex_value'])\n",
    "\n",
    "# Codificación por frecuencia para columnas con cardinalidad media\n",
    "medium_card_cols = [\n",
    "    'high_genre_dortmund_value', 'high_genre_rosamerica_value',\n",
    "    'high_genre_tzanetakis_value', 'high_ismir04_rhythm_value',\n",
    "    'audio_codec', 'low_key_key', 'low_chords_key'\n",
    "]\n",
    "df = frequency_encode(df, medium_card_cols)\n",
    "\n",
    "# Limpieza final (release year, nulos restantes)\n",
    "df = final_cleanup(df)\n",
    "\n",
    "# Escalar todas las columnas numéricas con StandardScaler\n",
    "df = scale_standard(df)\n",
    "\n",
    "# Vista previa final\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hitanalyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
